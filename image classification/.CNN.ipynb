def allcellimage(input_image_path):
    """
    """
    os.chdir(input_image_path)
    for root, dirs, files in os.walk(".", topdown = False):
        for name in dirs:
            os.chdir(input_image_path+"\\"+name)
            for root, dirs, files in os.walk(".", topdown = False):
                for filename in files:
                    input_path  =  (os.getcwd() + "\\"+ filename) 
                    img_16_bit  = imread(os.getcwd() + "\\"+ filename,-1) 
                    image = imread(input_path)
                    cell_image_all.append(image)
    return cell_image_all
   

def images_labels(label_image_path):
    """
    """
    os.chdir(label_image_path)
    image_labels   = pd.DataFrame()  # This has to be assign inside the local variable instead of global variable
    for root, dirs, files in os.walk(".", topdown = False):
        for name in dirs:
            os.chdir(label_image_path +"\\"+name)
            for root, dirs, files in os.walk(".", topdown = False):
                for filename in files:
                    input_path  =  (os.getcwd() + "\\"+ filename) 
                    label= pd.read_csv(input_path,header = None) # header = None means no header
                                                                 # otherwise, it uses first row as a header name 
                    image_labels = image_labels.append(label)    # with same column name, it will append to the same column            
    return image_labels

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0
train_images.shape
train_labels.shape
test_images.shape
#plt.imshow(train_images[0],cmap='gray')
test_labels.shape                              # no segmentation involved
test_labels[2000]   

model = models.Sequential()                         # declare a regular sequential model 
model.add(layers.Conv2D(32,(3,3),activation = 'relu',input_shape = (32,32,3)))
                                                     # add first hidden layer and clain input shape
                                                     # 32 means 32 types of kernel with 3x3 dimension,
                                                     # that means we have 32 layers, element wise
                                                     # final image shape is column number-2,row number -2 image become 30x30
model.add(layers.MaxPooling2D((2,2)))                # without stride it moves one by one, it reduces original
                                                     # dimension to half, image dimensioin become 15x15 
model.add(layers.Conv2D(64, (3,3), activation ='relu')) # adding second convoluation layer with 64 types of kernel filter
                                                        # image dimension become 13x13
    
model.add(layers.MaxPooling2D((2,2)))                   # image dimension become 6x6 as 13/2 = 6.5 => get lower ceiling    

model.add(layers.Conv2D(64,(3,3),activation='relu'))   # add third convolution layer, dimension becomes 4x4

#model.summary()                                        # forth parameter is called also channel 

model.add(layers.Dropout(0.2))                        # drop out 20% of output value from previous layer

#model.summary()                                        # forth parameter is called also channel 

model.add(layers.Flatten())                           # this layer changes 3D to 1D, 4x4x64 = 1024

model.add(layers.Dense(64,activation = 'relu'))      # this layer has 54 neurons

model.add(layers.Dense(10))                          # 10 classes

#model.summary()   

model.compile(optimizer = 'adam',
             loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
             metrics=['accuracy']
             )

#history = model.fit(train_images,train_labels,epochs = 10, validation_data = (test_images,test_labels))

#history.history['accuracy']

plt.plot(history.history['accuracy'], label='training_accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')
test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)

# training accuracy and validation accuracy are in same range not big margin this sample is good, if 
# training accuracy and validatino accuracy are off a lot, they are not good meaning model are overfitting

model.predict(train_images[:1])

    
